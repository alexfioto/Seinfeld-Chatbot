{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seinfeld Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "# Visualization library\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP library\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in entire Seinfeld script\n",
    "\n",
    "df = pd.read_csv('scripts.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>EpisodeNo</th>\n",
       "      <th>SEID</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>Do you know what this is all about? Do you kno...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>(pointing at Georges shirt) See, to me, that b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Are you through?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JERRY</td>\n",
       "      <td>You do of course try on, when you buy?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEORGE</td>\n",
       "      <td>Yes, it was purple, I liked it, I dont actuall...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>S01E01</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Character                                           Dialogue  EpisodeNo  \\\n",
       "0     JERRY  Do you know what this is all about? Do you kno...        1.0   \n",
       "1     JERRY  (pointing at Georges shirt) See, to me, that b...        1.0   \n",
       "2    GEORGE                                   Are you through?        1.0   \n",
       "3     JERRY             You do of course try on, when you buy?        1.0   \n",
       "4    GEORGE  Yes, it was purple, I liked it, I dont actuall...        1.0   \n",
       "\n",
       "     SEID  Season  \n",
       "0  S01E01     1.0  \n",
       "1  S01E01     1.0  \n",
       "2  S01E01     1.0  \n",
       "3  S01E01     1.0  \n",
       "4  S01E01     1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dialogue has stage directions included, indicated by parentheses. I have decided to remove them to just model on pure dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove parentheses\n",
    "\n",
    "df['clean_dialogue'] = df['Dialogue'].str.replace(r\"\\(.*\\)\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Character          0\n",
       "Dialogue          10\n",
       "EpisodeNo          0\n",
       "SEID               0\n",
       "Season             0\n",
       "clean_dialogue    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing there is 10 dialogue cells that are NaNs\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing NaNs\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the length of each line of dialogue\n",
    "\n",
    "df['dialogue_len'] = df['Dialogue'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the word count of each line of dialogue\n",
    "\n",
    "df['wordcount'] = df['clean_dialogue'].apply(lambda x: len(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing distribution of dialogue length in each line of dialogue\n",
    "\n",
    "sns.histplot(data=df, x='dialogue_len');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing the distribution of word count in each line of dialogue\n",
    "\n",
    "sns.histplot(data=df, x='wordcount');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few lines of dialogue that are quite long! Most of these are probably Jerry's monologues at the beginning of the episodes. I will limit the length of lines to aid training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving dataframe with dialogue length less than 50 characters\n",
    "\n",
    "df = df[df['dialogue_len']< 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the data is prepared for model. We need the data to be a list of lists with back and forth dialogue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Are you through?',\n",
       " 'You do of course try on, when you buy?',\n",
       " 'Oh, you dont recall?',\n",
       " 'Mr. Seinfeld. Mr. Costanza.',\n",
       " 'How come youre not doin the second show tomorrow?']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of all dialogue\n",
    "\n",
    "dialogue_list = list(df['clean_dialogue'])\n",
    "dialogue_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a data preparation function\n",
    "def seq_prep(dialogue):\n",
    "    '''\n",
    "    This function takes in a list of dialogue and returns a list\n",
    "    of lists in the appropriate format for our seq2seq model.\n",
    "    '''\n",
    "    dialogue_combos = []\n",
    "    for i in range(len(dialogue)+ 1):\n",
    "        try:\n",
    "            dialogue_combos.append([dialogue[i], dialogue[i+1]])\n",
    "        except:\n",
    "            pass\n",
    "    return dialogue_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Are you through?', 'You do of course try on, when you buy?'],\n",
       " ['You do of course try on, when you buy?', 'Oh, you dont recall?'],\n",
       " ['Oh, you dont recall?', 'Mr. Seinfeld. Mr. Costanza.'],\n",
       " ['Mr. Seinfeld. Mr. Costanza.',\n",
       "  'How come youre not doin the second show tomorrow?'],\n",
       " ['How come youre not doin the second show tomorrow?',\n",
       "  'Well, theres this uh, woman might be comin in.'],\n",
       " ['Well, theres this uh, woman might be comin in.', 'No, you didnt!']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = seq_prep(dialogue_list)\n",
    "data[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the prepared data as a pickle file\n",
    "with open('./data/seq2seq_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building empty lists to hold sentences\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "# Building empty vocabulary sets\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "for line in data[:3000]:\n",
    "  # Input and target sentences are separated by tabs\n",
    "  input_doc, target_doc = line[0], line[1]\n",
    "  # Appending each input sentence to input_docs\n",
    "  input_docs.append(input_doc)\n",
    "  # Splitting words from punctuation  \n",
    "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "  # Redefine target_doc below \n",
    "  # and append it to target_docs:\n",
    "  target_doc = '<START> ' + target_doc + ' <END>'\n",
    "  target_docs.append(target_doc)\n",
    "  \n",
    "  # Now we split up each sentence into words\n",
    "  # and add each unique word to our vocabulary set\n",
    "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "    # Add your code here:\n",
    "    if token not in input_tokens:\n",
    "      input_tokens.add(token)\n",
    "    \n",
    "  for token in target_doc.split():\n",
    "    # And here:\n",
    "    if token not in target_tokens:\n",
    "      target_tokens.add(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "# Create num_encoder_tokens and num_decoder_tokens:\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "# Finding the maximum \n",
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating four dictionaries\n",
    "\n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty matricies\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Input Data Shape: (3000, 21, 2210)\n",
      "Decoder Input Data Shape: (3000, 27, 2212)\n",
      "Decoder Target Data Shape: (3000, 27, 2212)\n"
     ]
    }
   ],
   "source": [
    "print(f'Encoder Input Data Shape: {encoder_input_data.shape}')\n",
    "print(f'Decoder Input Data Shape: {decoder_input_data.shape}')\n",
    "print(f'Decoder Target Data Shape: {decoder_target_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "\n",
    "  for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "    # Assign 1. for the current line, timestep, & word\n",
    "    # in encoder_input_data:\n",
    "    encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "    # add in conditional for handling unknown tokens (when token is not in input features dict)\n",
    "\n",
    "  for timestep, token in enumerate(target_doc.split()):\n",
    "\n",
    "    decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "    if timestep > 0:\n",
    "\n",
    "      decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  ('Are you through?',\n",
       "   '<START> You do of course try on , when you buy ? <END>')),\n",
       " (1,\n",
       "  ('You do of course try on, when you buy?',\n",
       "   '<START> Oh , you dont recall ? <END>')),\n",
       " (2,\n",
       "  ('Oh, you dont recall?', '<START> Mr . Seinfeld . Mr . Costanza . <END>')),\n",
       " (3,\n",
       "  ('Mr. Seinfeld. Mr. Costanza.',\n",
       "   '<START> How come youre not doin the second show tomorrow ? <END>')),\n",
       " (4,\n",
       "  ('How come youre not doin the second show tomorrow?',\n",
       "   '<START> Well , theres this uh , woman might be comin in . <END>')),\n",
       " (5,\n",
       "  ('Well, theres this uh, woman might be comin in.',\n",
       "   '<START> No , you didnt ! <END>')),\n",
       " (6, ('No, you didnt!', '<START> Ha . <END>')),\n",
       " (7, ('Ha.', '<START> So , you know , what , what happened ? <END>')),\n",
       " (8,\n",
       "  (' So, you know, what, what happened?',\n",
       "   '<START> Oh , nothing happened , you know , but is was great . <END>')),\n",
       " (9,\n",
       "  ('Oh, nothing happened, you know, but is was great.',\n",
       "   '<START> Oh , nothing happened , but it was . . . <END>')),\n",
       " (10, ('Oh, nothing happened, but it was...', '<START> Yeah . <END>')),\n",
       " (11, ('Yeah.', '<START> This is great ! <END>')),\n",
       " (12, ('This is great!', '<START> Yeah . <END>'))]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(zip(input_docs, target_docs)))[:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Of'), (1, 'what'), (2, '?')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(re.findall(r\"[\\w]+|[^\\s\\s]\", input_doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Of'), (1, 'what'), (2, '?')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(word_tokenize(input_doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing import num_encoder_tokens, num_decoder_tokens, decoder_target_data, encoder_input_data, decoder_input_data, decoder_target_data, max_encoder_seq_length, max_decoder_seq_length\n",
    "from tensorflow import keras\n",
    "# Add Dense to the imported layers\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "latent_dim = 256\n",
    "batch_size = 200\n",
    "epochs = 100\n",
    "\n",
    "# Encoder training setup\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder training setup:\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs,_ ,_ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code below was used to train my training model. Implemented in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 1.6054 - accuracy: 0.0358 - val_loss: 1.4070 - val_accuracy: 0.0415\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 8s 667ms/step - loss: 1.3265 - accuracy: 0.0446 - val_loss: 1.4024 - val_accuracy: 0.0450\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 8s 673ms/step - loss: 1.3029 - accuracy: 0.0476 - val_loss: 1.4025 - val_accuracy: 0.0428\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 8s 665ms/step - loss: 1.2879 - accuracy: 0.0480 - val_loss: 1.4151 - val_accuracy: 0.0457\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 8s 671ms/step - loss: 1.2789 - accuracy: 0.0491 - val_loss: 1.4168 - val_accuracy: 0.0387\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 8s 670ms/step - loss: 1.2708 - accuracy: 0.0487 - val_loss: 1.4185 - val_accuracy: 0.0449\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 8s 681ms/step - loss: 1.2635 - accuracy: 0.0515 - val_loss: 1.4218 - val_accuracy: 0.0494\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 8s 687ms/step - loss: 1.2550 - accuracy: 0.0533 - val_loss: 1.4312 - val_accuracy: 0.0500\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 1.2505 - accuracy: 0.0545 - val_loss: 1.4357 - val_accuracy: 0.0506\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 8s 696ms/step - loss: 1.2431 - accuracy: 0.0550 - val_loss: 1.4358 - val_accuracy: 0.0482\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 9s 709ms/step - loss: 1.2319 - accuracy: 0.0566 - val_loss: 1.4370 - val_accuracy: 0.0480\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 1.2255 - accuracy: 0.0586 - val_loss: 1.4416 - val_accuracy: 0.0491\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 9s 716ms/step - loss: 1.2187 - accuracy: 0.0622 - val_loss: 1.4458 - val_accuracy: 0.0515\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 9s 724ms/step - loss: 1.2074 - accuracy: 0.0638 - val_loss: 1.4551 - val_accuracy: 0.0572\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 1.2001 - accuracy: 0.0662 - val_loss: 1.4475 - val_accuracy: 0.0525\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 9s 723ms/step - loss: 1.1926 - accuracy: 0.0669 - val_loss: 1.4256 - val_accuracy: 0.0612\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 9s 743ms/step - loss: 1.1815 - accuracy: 0.0695 - val_loss: 1.4296 - val_accuracy: 0.0583\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 9s 729ms/step - loss: 1.1700 - accuracy: 0.0707 - val_loss: 1.4254 - val_accuracy: 0.0623\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 9s 742ms/step - loss: 1.1617 - accuracy: 0.0720 - val_loss: 1.4281 - val_accuracy: 0.0623\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 9s 737ms/step - loss: 1.1527 - accuracy: 0.0731 - val_loss: 1.4199 - val_accuracy: 0.0641\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 9s 746ms/step - loss: 1.1422 - accuracy: 0.0741 - val_loss: 1.4135 - val_accuracy: 0.0664\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 9s 747ms/step - loss: 1.1344 - accuracy: 0.0750 - val_loss: 1.4052 - val_accuracy: 0.0651\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 9s 744ms/step - loss: 1.1221 - accuracy: 0.0759 - val_loss: 1.4001 - val_accuracy: 0.0668\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 9s 760ms/step - loss: 1.1112 - accuracy: 0.0772 - val_loss: 1.4005 - val_accuracy: 0.0658\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 9s 765ms/step - loss: 1.1066 - accuracy: 0.0774 - val_loss: 1.4007 - val_accuracy: 0.0667\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 9s 750ms/step - loss: 1.0961 - accuracy: 0.0776 - val_loss: 1.3973 - val_accuracy: 0.0662\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 9s 743ms/step - loss: 1.0850 - accuracy: 0.0786 - val_loss: 1.4002 - val_accuracy: 0.0664\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 9s 744ms/step - loss: 1.0796 - accuracy: 0.0792 - val_loss: 1.3854 - val_accuracy: 0.0677\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 9s 739ms/step - loss: 1.0698 - accuracy: 0.0799 - val_loss: 1.3853 - val_accuracy: 0.0696\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 9s 732ms/step - loss: 1.0610 - accuracy: 0.0803 - val_loss: 1.3790 - val_accuracy: 0.0699\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 9s 727ms/step - loss: 1.0530 - accuracy: 0.0810 - val_loss: 1.3708 - val_accuracy: 0.0709\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 1.0417 - accuracy: 0.0829 - val_loss: 1.3922 - val_accuracy: 0.0694\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 9s 736ms/step - loss: 1.0362 - accuracy: 0.0831 - val_loss: 1.3760 - val_accuracy: 0.0707\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 1.0272 - accuracy: 0.0843 - val_loss: 1.3695 - val_accuracy: 0.0723\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 1.0168 - accuracy: 0.0854 - val_loss: 1.3818 - val_accuracy: 0.0675\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 9s 718ms/step - loss: 1.0084 - accuracy: 0.0854 - val_loss: 1.3683 - val_accuracy: 0.0698\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 9s 718ms/step - loss: 1.0012 - accuracy: 0.0865 - val_loss: 1.3621 - val_accuracy: 0.0710\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 9s 713ms/step - loss: 0.9913 - accuracy: 0.0886 - val_loss: 1.3815 - val_accuracy: 0.0692\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.9842 - accuracy: 0.0889 - val_loss: 1.3586 - val_accuracy: 0.0738\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 9s 709ms/step - loss: 0.9742 - accuracy: 0.0894 - val_loss: 1.3534 - val_accuracy: 0.0754\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 8s 703ms/step - loss: 0.9668 - accuracy: 0.0905 - val_loss: 1.3571 - val_accuracy: 0.0744\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 9s 715ms/step - loss: 0.9581 - accuracy: 0.0913 - val_loss: 1.3609 - val_accuracy: 0.0756\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.9477 - accuracy: 0.0933 - val_loss: 1.3595 - val_accuracy: 0.0757\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 9s 720ms/step - loss: 0.9433 - accuracy: 0.0934 - val_loss: 1.3578 - val_accuracy: 0.0736\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.9338 - accuracy: 0.0930 - val_loss: 1.3543 - val_accuracy: 0.0757\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.9252 - accuracy: 0.0948 - val_loss: 1.3501 - val_accuracy: 0.0813\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 9s 713ms/step - loss: 0.9166 - accuracy: 0.0962 - val_loss: 1.3511 - val_accuracy: 0.0772\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 9s 717ms/step - loss: 0.9106 - accuracy: 0.0993 - val_loss: 1.3470 - val_accuracy: 0.0766\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 9s 721ms/step - loss: 0.8997 - accuracy: 0.1006 - val_loss: 1.3662 - val_accuracy: 0.0746\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.8911 - accuracy: 0.0998 - val_loss: 1.3642 - val_accuracy: 0.0741\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 8s 699ms/step - loss: 0.8902 - accuracy: 0.0978 - val_loss: 1.3446 - val_accuracy: 0.0762\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 9s 710ms/step - loss: 0.8784 - accuracy: 0.1023 - val_loss: 1.3501 - val_accuracy: 0.0751\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 9s 713ms/step - loss: 0.8691 - accuracy: 0.1020 - val_loss: 1.3469 - val_accuracy: 0.0768\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 0.8646 - accuracy: 0.1032 - val_loss: 1.3477 - val_accuracy: 0.0849\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 9s 722ms/step - loss: 0.8550 - accuracy: 0.1088 - val_loss: 1.3602 - val_accuracy: 0.0781\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.8473 - accuracy: 0.1065 - val_loss: 1.3474 - val_accuracy: 0.0751\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.8428 - accuracy: 0.1060 - val_loss: 1.3392 - val_accuracy: 0.0800\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.8337 - accuracy: 0.1131 - val_loss: 1.3443 - val_accuracy: 0.0778\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 9s 731ms/step - loss: 0.8267 - accuracy: 0.1101 - val_loss: 1.3421 - val_accuracy: 0.0765\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 9s 727ms/step - loss: 0.8217 - accuracy: 0.1110 - val_loss: 1.3475 - val_accuracy: 0.0773\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.8104 - accuracy: 0.1165 - val_loss: 1.3539 - val_accuracy: 0.0769\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 9s 715ms/step - loss: 0.8051 - accuracy: 0.1119 - val_loss: 1.3490 - val_accuracy: 0.0826\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 9s 729ms/step - loss: 0.7958 - accuracy: 0.1149 - val_loss: 1.3488 - val_accuracy: 0.0833\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.7886 - accuracy: 0.1140 - val_loss: 1.3533 - val_accuracy: 0.0769\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 9s 723ms/step - loss: 0.7837 - accuracy: 0.1240 - val_loss: 1.3527 - val_accuracy: 0.0748\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.7764 - accuracy: 0.1175 - val_loss: 1.3545 - val_accuracy: 0.0814\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.7678 - accuracy: 0.1189 - val_loss: 1.3678 - val_accuracy: 0.0801\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 9s 729ms/step - loss: 0.7613 - accuracy: 0.1253 - val_loss: 1.3558 - val_accuracy: 0.0776\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.7561 - accuracy: 0.1224 - val_loss: 1.3592 - val_accuracy: 0.0900\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.7462 - accuracy: 0.1245 - val_loss: 1.3521 - val_accuracy: 0.0900\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.7398 - accuracy: 0.1240 - val_loss: 1.3605 - val_accuracy: 0.0787\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 9s 710ms/step - loss: 0.7355 - accuracy: 0.1246 - val_loss: 1.3612 - val_accuracy: 0.0790\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 9s 710ms/step - loss: 0.7255 - accuracy: 0.1277 - val_loss: 1.3751 - val_accuracy: 0.0766\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 8s 701ms/step - loss: 0.7188 - accuracy: 0.1297 - val_loss: 1.3781 - val_accuracy: 0.0773\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 8s 688ms/step - loss: 0.7143 - accuracy: 0.1268 - val_loss: 1.3696 - val_accuracy: 0.1060\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 8s 690ms/step - loss: 0.7051 - accuracy: 0.1309 - val_loss: 1.3687 - val_accuracy: 0.0864\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 9s 709ms/step - loss: 0.7010 - accuracy: 0.1310 - val_loss: 1.3725 - val_accuracy: 0.0782\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.6944 - accuracy: 0.1337 - val_loss: 1.3565 - val_accuracy: 0.0866\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 9s 722ms/step - loss: 0.6879 - accuracy: 0.1356 - val_loss: 1.3627 - val_accuracy: 0.0811\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 0.6779 - accuracy: 0.1366 - val_loss: 1.3704 - val_accuracy: 0.0759\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.6754 - accuracy: 0.1359 - val_loss: 1.3862 - val_accuracy: 0.0828\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.6624 - accuracy: 0.1399 - val_loss: 1.3843 - val_accuracy: 0.0845\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 9s 722ms/step - loss: 0.6604 - accuracy: 0.1412 - val_loss: 1.3781 - val_accuracy: 0.0834\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 9s 730ms/step - loss: 0.6541 - accuracy: 0.1406 - val_loss: 1.3841 - val_accuracy: 0.0788\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 0.6478 - accuracy: 0.1539 - val_loss: 1.3840 - val_accuracy: 0.0775\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.6391 - accuracy: 0.1487 - val_loss: 1.3843 - val_accuracy: 0.0777\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 9s 713ms/step - loss: 0.6318 - accuracy: 0.1479 - val_loss: 1.3912 - val_accuracy: 0.0938\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 9s 716ms/step - loss: 0.6249 - accuracy: 0.1531 - val_loss: 1.3869 - val_accuracy: 0.0797\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 9s 725ms/step - loss: 0.6215 - accuracy: 0.1523 - val_loss: 1.4045 - val_accuracy: 0.1473\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 9s 725ms/step - loss: 0.6121 - accuracy: 0.1571 - val_loss: 1.4030 - val_accuracy: 0.0778\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.6082 - accuracy: 0.1656 - val_loss: 1.3984 - val_accuracy: 0.1199\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 0.6017 - accuracy: 0.1564 - val_loss: 1.4145 - val_accuracy: 0.0958\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.5959 - accuracy: 0.1607 - val_loss: 1.4068 - val_accuracy: 0.0920\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.5880 - accuracy: 0.1595 - val_loss: 1.4173 - val_accuracy: 0.0960\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 8s 708ms/step - loss: 0.5787 - accuracy: 0.1563 - val_loss: 1.4196 - val_accuracy: 0.0773\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 9s 735ms/step - loss: 0.5806 - accuracy: 0.1636 - val_loss: 1.4169 - val_accuracy: 0.0736\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.5676 - accuracy: 0.1650 - val_loss: 1.4097 - val_accuracy: 0.0864\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 0.5635 - accuracy: 0.1719 - val_loss: 1.4222 - val_accuracy: 0.0725\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.5590 - accuracy: 0.1646 - val_loss: 1.4239 - val_accuracy: 0.1154\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 8s 692ms/step - loss: 0.5506 - accuracy: 0.1688 - val_loss: 1.4185 - val_accuracy: 0.0836\n"
     ]
    }
   ],
   "source": [
    "# Building the training model:\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
    "\n",
    "history = training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, \n",
    "                    validation_split = 0.2)\n",
    "\n",
    "training_model.save('/Users/alexander.fioto/Models/training_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing import input_features_dict, target_features_dict, reverse_input_features_dict, reverse_target_features_dict, max_decoder_seq_length, input_docs, target_docs, input_tokens, target_tokens, max_encoder_seq_length\n",
    "#from training_model import decoder_inputs, decoder_lstm, decoder_dense, encoder_input_data, num_decoder_tokens, num_encoder_tokens\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "\n",
    "# training_model = load_model('training_model.h5')\n",
    "\n",
    "# encoder_inputs = training_model.input[0]\n",
    "# encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "# encoder_states = [state_h_enc, state_c_enc]\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "latent_dim = 256\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(test_input):\n",
    "  # Encode the input as state vectors.\n",
    "  states_value = encoder_model.predict(test_input)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "  # Populate the first token of target sequence with the start token.\n",
    "  target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "\n",
    "  # Sampling loop for a batch of sequences\n",
    "  # (to simplify, here we assume a batch of size 1).\n",
    "  decoded_sentence = ''\n",
    "\n",
    "  stop_condition = False\n",
    "  while not stop_condition:\n",
    "    # Run the decoder model to get possible \n",
    "    # output tokens (with probabilities) & states\n",
    "    output_tokens, hidden_state, cell_state = decoder_model.predict(\n",
    "      [target_seq] + states_value)\n",
    "\n",
    "    # Choose token with highest probability\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "    decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "    # Exit condition: either hit max length\n",
    "    # or find stop token.\n",
    "    if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "      stop_condition = True\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # Update states\n",
    "    states_value = [hidden_state, cell_state]\n",
    "\n",
    "  return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-f217d175adf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'What are you doing?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-f312c0d9895a>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[0;34m(test_input)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# Encode the input as state vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mstates_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Generate empty target sequence of length 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    885\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "decode_sequence('What are you doing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "\n",
    "\n",
    "    exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\", 'end')\n",
    "\n",
    "    def start_chat(self):\n",
    "        user_response = input(\"Hi, I'm a chatbot trained on dialog from Seinfeld. Would you like to chat with me?\\n\")\n",
    "    \n",
    "        if user_response.lower() in self.negative_responses:\n",
    "            print(\"Ok, have a great day!\")\n",
    "            return\n",
    "    \n",
    "        user_response = input('Great! I am still a work in progress. Try using a lot of different words when chatting with me. Ok, what do you want to talk about?')\n",
    "    \n",
    "        self.chat(user_response)\n",
    "  \n",
    "    def chat(self, reply):\n",
    "        while not self.make_exit(reply):\n",
    "            reply = input(self.generate_response(reply))\n",
    "    \n",
    "\n",
    "    def string_to_matrix(self, user_input):\n",
    "        tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "        user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "        for timestep, token in enumerate(tokens):\n",
    "            if token in input_features_dict:\n",
    "                user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "\n",
    "        return user_input_matrix\n",
    "\n",
    "    def generate_response(self, user_input):\n",
    "        input_matrix = self.string_to_matrix(user_input)\n",
    "        states_value = encoder_model.predict(input_matrix)\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, target_features_dict['<START>']] = 1.0\n",
    "    \n",
    "        chatbot_response = ''\n",
    "\n",
    "        stop_condition = False\n",
    "\n",
    "        while not stop_condition:\n",
    "\n",
    "            output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "            chatbot_response += \" \" + sampled_token\n",
    "\n",
    "            if (sampled_token == '<END>' or len(chatbot_response) > max_decoder_seq_length):\n",
    "                stop_condition = True\n",
    "\n",
    "                target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "                target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "            if '<END>' in chatbot_response:\n",
    "                chatbot_response = chatbot_response.replace('<END>', '')\n",
    "\n",
    "            punctuations = [' ?', ' .', ' !', ' ,']            \n",
    "            for punctuation in punctuations:\n",
    "                if punctuation in chatbot_response:\n",
    "                    chatbot_response = chatbot_response.replace(punctuation, punctuation[-1])\n",
    "\n",
    "\n",
    "            states_value = [hidden_state, cell_state]\n",
    "\n",
    "        return chatbot_response\n",
    "  \n",
    "    def make_exit(self, reply):\n",
    "        for exit_command in self.exit_commands:\n",
    "            if exit_command in reply:\n",
    "                print(\"Ok, have a great day!\")\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot trained on dialog from Seinfeld. Would you like to chat with me?\n",
      " Yes\n",
      "Great! I am still a work in progress. Try using a lot of different words when chatting with me. Ok, what do you want to talk about? What is your favorite food\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-7dcd8258feef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-82-ebdca281bcd4>\u001b[0m in \u001b[0;36mstart_chat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0muser_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Great! I am still a work in progress. Try using a lot of different words when chatting with me. Ok, what do you want to talk about?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-ebdca281bcd4>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, reply)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "chat.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
