{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab Notebook - GTP2 / aitextgen Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9PqnnfjGLpdl",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "c9c7eeeb-833e-4799-b3a9-b60dffaed695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.9.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 4.7MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 19.6MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 16.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (1.18.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (4.41.1)\n",
      "Collecting tokenizers==0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.8MB 47.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2.23.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.7)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (3.0.12)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (0.17.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2020.6.20)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=6501f2915148bd9e1e1fcebf2921fe5445ca56e2693ff97f23114cbd310eac9d\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.9.1\n",
      "Collecting pytorch-lightning==0.7.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/ab/561d1fa6e5af30b2fd7cb4001f93eb08531e1b72976f13eebf7f7cdc021c/pytorch_lightning-0.7.6-py3-none-any.whl (248kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 4.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (1.18.5)\n",
      "Requirement already satisfied: pyyaml>=3.13 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (3.13)\n",
      "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (1.7.0+cu101)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (4.41.1)\n",
      "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.6) (2.3.0)\n",
      "Collecting future>=0.17.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 14.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch-lightning==0.7.6) (3.7.4.3)\n",
      "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1->pytorch-lightning==0.7.6) (0.7)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (3.12.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (50.3.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (0.35.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.17.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (0.10.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.7.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (2.23.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (0.4.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (1.33.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.7.6) (3.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.6) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.6) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.6) (0.2.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.6) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.6) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.6) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning==0.7.6) (1.24.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.7.6) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.6) (2.0.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.7.6) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.7.6) (3.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.7.6) (3.4.0)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491057 sha256=5d94b1eb57f77f5fa99507a9b611b985c71e23fc1b113e417b8b84b2c9afe061\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "Successfully built future\n",
      "Installing collected packages: future, pytorch-lightning\n",
      "  Found existing installation: future 0.16.0\n",
      "    Uninstalling future-0.16.0:\n",
      "      Successfully uninstalled future-0.16.0\n",
      "Successfully installed future-0.18.2 pytorch-lightning-0.7.6\n",
      "\u001b[K     |████████████████████████████████| 573kB 4.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 81kB 7.3MB/s \n",
      "\u001b[?25h  Building wheel for aitextgen (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/10/2020 16:57:23 — INFO — transformers.file_utils — PyTorch version 1.7.0+cu101 available.\n",
      "11/10/2020 16:57:24 — INFO — transformers.file_utils — TensorFlow version 2.3.0 available.\n"
     ]
    }
   ],
   "source": [
    "# Freeze versions of dependencies for now\n",
    "!pip install transformers==2.9.1\n",
    "!pip install pytorch-lightning==0.7.6\n",
    "\n",
    "!pip install -q aitextgen\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s — %(levelname)s — %(name)s — %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO\n",
    "    )\n",
    "\n",
    "from aitextgen import aitextgen\n",
    "from aitextgen.colab import mount_gdrive, copy_file_from_gdrive\n",
    "from aitextgen.TokenDataset import TokenDataset, merge_datasets\n",
    "from aitextgen.utils import build_gpt2_config\n",
    "from aitextgen.tokenizers import train_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HiK11siGLx7f",
    "outputId": "9ba350f7-1f5e-4b6a-840b-ffdf40f70678"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 10 16:57:26 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rye4hwAmL2mt",
    "outputId": "bd83b6a8-4a9e-4d9b-84b0-53704512ecc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting Google Drive\n",
    "mount_gdrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2WtTPRnL_IS"
   },
   "outputs": [],
   "source": [
    "# Labeling filename from Google Drive\n",
    "file_name = 'labeled_seinfeld_dialogue.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wq1gs1xZMe5o"
   },
   "outputs": [],
   "source": [
    "# Copying file from Google Drive\n",
    "copy_file_from_gdrive(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQChaOm3OYNg",
    "outputId": "3912cf42-de75-42ab-8a63-c068f1450421"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/10/2020 16:57:56 — INFO — aitextgen.tokenizers — Saving aitextgen-vocab.json and aitextgen-merges.txt to the current directory. You will need both files to build the GPT2Tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# Training the tokenizer\n",
    "train_tokenizer(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05mutHBQMjC2",
    "outputId": "c55c2a2b-9dd7-49ee-a944-7c14152a3790"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"attn_pdrop\": 0.0,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"embd_pdrop\": 0.0,\n",
       "  \"eos_token_id\": 0,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 100,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 8,\n",
       "  \"n_layer\": 8,\n",
       "  \"n_positions\": 100,\n",
       "  \"resid_pdrop\": 0.0,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.0,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"vocab_size\": 5000\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuring GPT2 \n",
    "config = build_gpt2_config(vocab_size=5000, \n",
    "                           max_length=100, \n",
    "                           dropout=0.0,  \n",
    "                           n_layer=8, \n",
    "                           n_head=8)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zcfq5hz-OI0i",
    "outputId": "a99864ff-4704-4373-f857-27a92c83b0b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/10/2020 16:58:07 — INFO — aitextgen — Constructing GPT-2 model from provided config.\n",
      "11/10/2020 16:58:09 — INFO — aitextgen — Using a custom tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "ai = aitextgen(config=config,\n",
    "               vocab_file=\"aitextgen-vocab.json\",\n",
    "               merges_file=\"aitextgen-merges.txt\",\n",
    "               to_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "37815042dcbb4e13b72d88c6d9e6bf87",
      "85eaaf5a947b42268336c674a787bb1b",
      "206bf162fcac4c77a7a7cc9d66a381f4",
      "00380131c3ab41daa3b90d9ac671b934",
      "5329e8631acd4e88a30943e561309eed",
      "b57a68ff9ab74ca7b2e22e76f777ca1d",
      "adb2d787c3424730b48c20880d2ca7c3",
      "2a9fe3fd2dc44a859c787b86a34a6999",
      "d89265af125d4628848c9e78c5a3abd9",
      "b215755c00af46678864324bae6877bc",
      "9d688da4d9f44540ad5e52877e4caa76",
      "e1966779b7a6479e90bbff38e9fed0fd",
      "200d98c62ff94c8db9a938b0fc9148eb",
      "69560c63928b4a03a94b4be476c3c789",
      "839a22d416424c979880c98ed7d05ceb",
      "9011f65dc64f4db580b06cbdf766bfa1"
     ]
    },
    "id": "LWIYuZj1ORO8",
    "outputId": "58b6398c-29bd-472d-f366-81e03b7bd778"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37815042dcbb4e13b72d88c6d9e6bf87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=327636.0), HTML(value='')), layout=Layout…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/10/2020 16:58:23 — INFO — aitextgen.TokenDataset — Encoding 327,636 sets of tokens from labeled_seinfeld_dialogue.txt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "11/10/2020 16:58:27 — INFO — lightning — GPU available: True, used: True\n",
      "No environment variable for node rank defined. Set as 0.\n",
      "11/10/2020 16:58:27 — WARNING — lightning — No environment variable for node rank defined. Set as 0.\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "11/10/2020 16:58:27 — INFO — lightning — CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89265af125d4628848c9e78c5a3abd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=5000.0), HTML(value='')), layout=Layout(d…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m1,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " to be a man?\n",
      "\n",
      "\n",
      "JERRY: Oh, yeah.\n",
      "\n",
      "\n",
      "KRAMER: All right. \n",
      "\n",
      "\n",
      "JERRY: So, how's the ticket?\n",
      "\n",
      "\n",
      "KRAMER: Well, I'm getting married to the airport.\n",
      "\n",
      "\n",
      "ELAINE: Uh, what's the matter?\n",
      "\n",
      "\n",
      "KRAMER: Well, I just think I'm a wonderful guy.\n",
      "\n",
      "\n",
      "ELAINE: What?\n",
      "\n",
      "\n",
      "KRAMER: I can't go to the bathroom.\n",
      "\n",
      "\n",
      "==========\n",
      "\u001b[1m2,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m2,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      " a lot of problems.\n",
      "\n",
      "\n",
      "GEORGE:  You know, if you think about it, I take it, I want you to do me a favor.\n",
      "\n",
      "\n",
      "JERRY:  No, I'm not gonna get the Cadillac.\n",
      "\n",
      "\n",
      "KRAMER:  Hey.\n",
      "\n",
      "\n",
      "JERRY: Hey.\n",
      "\n",
      "\n",
      "KRAMER: Hey, Kramer.\n",
      "\n",
      "\n",
      "JERRY: Hey, hey. What's with you?\n",
      "\n",
      "\n",
      "KRAMER: Oh, I think I had a\n",
      "==========\n",
      "\u001b[1m3,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m3,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ".\n",
      "\n",
      "\n",
      "GEORGE:  Here.\n",
      "\n",
      "\n",
      "KRAMER: Hey, hey, hey. I dig.\n",
      "\n",
      "\n",
      "ELAINE: I just remembered... uh..\n",
      "\n",
      "\n",
      "KRAMER: What?\n",
      "\n",
      "\n",
      "ELAINE: What?\n",
      "\n",
      "\n",
      "KRAMER: Yeah, I just wanted to know what time it was.\n",
      "\n",
      "\n",
      "ELAINE: All right, geh, forget, it's not the first day.\n",
      "\n",
      "\n",
      "KRAMER: No, no, I don't\n",
      "==========\n",
      "\u001b[1m4,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m4,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      "!\n",
      "\n",
      "\n",
      "I didn't know it was yours.\n",
      "\n",
      "\n",
      "I bet the pen's almost funny.\n",
      "\n",
      "\n",
      "Loboes?\n",
      "\n",
      "\n",
      "This is your very a coupleness.\n",
      "\n",
      "\n",
      "I'm enthusiastic.\n",
      "\n",
      "\n",
      "Hey, hey, hey!\n",
      "\n",
      "\n",
      "Missie Clean.\n",
      "\n",
      "\n",
      "All right, great.\n",
      "\n",
      "\n",
      "You're under arrest.\n",
      "\n",
      "\n",
      "Hey, you know.\n",
      "\n",
      "\n",
      "What's\n",
      "==========\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/10/2020 17:56:56 — INFO — aitextgen — Saving trained model pytorch_model.bin to /trained_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      ".\n",
      "\n",
      "\n",
      "You got mothers fur coat for pist.\n",
      "\n",
      "\n",
      "Oh, whoa, do you think?\n",
      "\n",
      "\n",
      "Hey, let me ask you something, you know any women we should call her.\n",
      "\n",
      "\n",
      "Really?\n",
      "\n",
      "\n",
      "I know what's wrong with her.\n",
      "\n",
      "\n",
      "What?\n",
      "\n",
      "\n",
      "She probably never started the nurse.\n",
      "\n",
      "\n",
      "Yeah, she's great. She's just like me, if she's sing in\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "ai.train(file_name,\n",
    "         line_by_line=False,\n",
    "         num_steps=5000,\n",
    "         generate_every=1000,\n",
    "         save_every=1000,\n",
    "         save_gdrive=False,\n",
    "         learning_rate=1e-4,\n",
    "         batch_size=100,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9FMLE75SyNp",
    "outputId": "1a6f3d16-2a45-484e-bfe0-c4fe0401393f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mALEX: I want to talk to Jerry and Kramer.\u001b[0m\n",
      "\n",
      "\n",
      "KRAMER:  Well, Kramer.\n",
      "\n",
      "\n",
      "KATIE: Okay listen, I need you to help me move my refrigerator.\n",
      "\n",
      "\n",
      "JERRY: What d'you do?\n",
      "\n",
      "\n",
      "KATIE: It's your first time I've ever given your number.\n",
      "\n",
      "\n",
      "JERRY: It's just such a good idea.\n",
      "\n",
      "\n",
      "KATIE: Okay.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generating a single output\n",
    "ai.generate(n=1,\n",
    "            batch_size=1,\n",
    "            prompt=\"ALEX: I want to talk to Jerry and Kramer.\",\n",
    "            temperature=0.4,\n",
    "            top_p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBCrnK2boJZn"
   },
   "outputs": [],
   "source": [
    "# Generating an output to a list\n",
    "text =ai.generate(n=1,\n",
    "                  batch_size=1,\n",
    "                  max_len=16,\n",
    "                  prompt=\"ALEX: I don't understand what you are talking about?\",\n",
    "                  temperature=0.8,\n",
    "                  top_p=0.9,\n",
    "                  return_as_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYhVNMA_TAvX"
   },
   "outputs": [],
   "source": [
    "gen_list = text[0].split('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tWCIy1REWEX1",
    "outputId": "2249df5e-f7e6-41af-c22b-5f7fdc034896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALEX: I don't understand what you are talking about? We will be making you!\n",
      "\n",
      "\n",
      "JERRY: Where do you always?\n"
     ]
    }
   ],
   "source": [
    "print(gen_list[0] + '\\n\\n\\n' + gen_list[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "seinfeld-GPT-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00380131c3ab41daa3b90d9ac671b934": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a9fe3fd2dc44a859c787b86a34a6999",
      "placeholder": "​",
      "style": "IPY_MODEL_adb2d787c3424730b48c20880d2ca7c3",
      "value": " 327636/327636 [00:04&lt;00:00, 78899.86it/s]"
     }
    },
    "200d98c62ff94c8db9a938b0fc9148eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "206bf162fcac4c77a7a7cc9d66a381f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b57a68ff9ab74ca7b2e22e76f777ca1d",
      "max": 327636,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5329e8631acd4e88a30943e561309eed",
      "value": 327636
     }
    },
    "2a9fe3fd2dc44a859c787b86a34a6999": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37815042dcbb4e13b72d88c6d9e6bf87": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_206bf162fcac4c77a7a7cc9d66a381f4",
       "IPY_MODEL_00380131c3ab41daa3b90d9ac671b934"
      ],
      "layout": "IPY_MODEL_85eaaf5a947b42268336c674a787bb1b"
     }
    },
    "5329e8631acd4e88a30943e561309eed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "69560c63928b4a03a94b4be476c3c789": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "839a22d416424c979880c98ed7d05ceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85eaaf5a947b42268336c674a787bb1b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "9011f65dc64f4db580b06cbdf766bfa1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d688da4d9f44540ad5e52877e4caa76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Loss: 0.351 — Avg: 0.362 — GPU Mem: 11195 MB: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69560c63928b4a03a94b4be476c3c789",
      "max": 5000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_200d98c62ff94c8db9a938b0fc9148eb",
      "value": 5000
     }
    },
    "adb2d787c3424730b48c20880d2ca7c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b215755c00af46678864324bae6877bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "b57a68ff9ab74ca7b2e22e76f777ca1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d89265af125d4628848c9e78c5a3abd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d688da4d9f44540ad5e52877e4caa76",
       "IPY_MODEL_e1966779b7a6479e90bbff38e9fed0fd"
      ],
      "layout": "IPY_MODEL_b215755c00af46678864324bae6877bc"
     }
    },
    "e1966779b7a6479e90bbff38e9fed0fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9011f65dc64f4db580b06cbdf766bfa1",
      "placeholder": "​",
      "style": "IPY_MODEL_839a22d416424c979880c98ed7d05ceb",
      "value": " 5000/5000 [58:40&lt;00:00,  1.42it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
