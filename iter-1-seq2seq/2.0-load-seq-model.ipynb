{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/seq2seq_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building empty lists to hold sentences\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "# Building empty vocabulary sets\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "for line in data[:3000]:\n",
    "    # Input and target sentences are separated by tabs\n",
    "    input_doc, target_doc = line[0], line[1]\n",
    "    # Appending each input sentence to input_docs\n",
    "    input_docs.append(input_doc)\n",
    "    # Splitting words from punctuation  \n",
    "    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "    # Redefine target_doc below \n",
    "    # and append it to target_docs:\n",
    "    target_doc = '<START> ' + target_doc + ' <END>'\n",
    "    target_docs.append(target_doc)\n",
    "  \n",
    "  # Now we split up each sentence into words\n",
    "  # and add each unique word to our vocabulary set\n",
    "    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "    # Add your code here:\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "\n",
    "    for token in target_doc.split():\n",
    "    # And here:\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "# Create num_encoder_tokens and num_decoder_tokens:\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "# Finding the maximum \n",
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating four dictionaries\n",
    "\n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty matricies\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Input Data Shape: (3000, 21, 2210)\n",
      "Decoder Input Data Shape: (3000, 27, 2212)\n",
      "Decoder Target Data Shape: (3000, 27, 2212)\n"
     ]
    }
   ],
   "source": [
    "print(f'Encoder Input Data Shape: {encoder_input_data.shape}')\n",
    "print(f'Decoder Input Data Shape: {decoder_input_data.shape}')\n",
    "print(f'Decoder Target Data Shape: {decoder_target_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "    # Assign 1. for the current line, timestep, & word\n",
    "    # in encoder_input_data:\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "    # add in conditional for handling unknown tokens (when token is not in input features dict)\n",
    "\n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "        if timestep > 0:\n",
    "\n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  ('Are you through?',\n",
       "   '<START> You do of course try on , when you buy ? <END>')),\n",
       " (1,\n",
       "  ('You do of course try on, when you buy?',\n",
       "   '<START> Oh , you dont recall ? <END>')),\n",
       " (2,\n",
       "  ('Oh, you dont recall?', '<START> Mr . Seinfeld . Mr . Costanza . <END>')),\n",
       " (3,\n",
       "  ('Mr. Seinfeld. Mr. Costanza.',\n",
       "   '<START> How come youre not doin the second show tomorrow ? <END>')),\n",
       " (4,\n",
       "  ('How come youre not doin the second show tomorrow?',\n",
       "   '<START> Well , theres this uh , woman might be comin in . <END>'))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(zip(input_docs, target_docs)))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Of'), (1, 'what'), (2, '?')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(re.findall(r\"[\\w]+|[^\\s\\s]\", input_doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Of'), (1, 'what'), (2, '?')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(word_tokenize(input_doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing import num_encoder_tokens, num_decoder_tokens, decoder_target_data, encoder_input_data, decoder_input_data, decoder_target_data, max_encoder_seq_length, max_decoder_seq_length\n",
    "from tensorflow import keras\n",
    "# Add Dense to the imported layers\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "latent_dim = 256\n",
    "batch_size = 200\n",
    "epochs = 100\n",
    "\n",
    "# Encoder training setup\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder training setup:\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs,_ ,_ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code below was used to train my training model. Implemented in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 1.6054 - accuracy: 0.0358 - val_loss: 1.4070 - val_accuracy: 0.0415\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 8s 667ms/step - loss: 1.3265 - accuracy: 0.0446 - val_loss: 1.4024 - val_accuracy: 0.0450\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 8s 673ms/step - loss: 1.3029 - accuracy: 0.0476 - val_loss: 1.4025 - val_accuracy: 0.0428\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 8s 665ms/step - loss: 1.2879 - accuracy: 0.0480 - val_loss: 1.4151 - val_accuracy: 0.0457\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 8s 671ms/step - loss: 1.2789 - accuracy: 0.0491 - val_loss: 1.4168 - val_accuracy: 0.0387\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 8s 670ms/step - loss: 1.2708 - accuracy: 0.0487 - val_loss: 1.4185 - val_accuracy: 0.0449\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 8s 681ms/step - loss: 1.2635 - accuracy: 0.0515 - val_loss: 1.4218 - val_accuracy: 0.0494\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 8s 687ms/step - loss: 1.2550 - accuracy: 0.0533 - val_loss: 1.4312 - val_accuracy: 0.0500\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 1.2505 - accuracy: 0.0545 - val_loss: 1.4357 - val_accuracy: 0.0506\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 8s 696ms/step - loss: 1.2431 - accuracy: 0.0550 - val_loss: 1.4358 - val_accuracy: 0.0482\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 9s 709ms/step - loss: 1.2319 - accuracy: 0.0566 - val_loss: 1.4370 - val_accuracy: 0.0480\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 1.2255 - accuracy: 0.0586 - val_loss: 1.4416 - val_accuracy: 0.0491\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 9s 716ms/step - loss: 1.2187 - accuracy: 0.0622 - val_loss: 1.4458 - val_accuracy: 0.0515\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 9s 724ms/step - loss: 1.2074 - accuracy: 0.0638 - val_loss: 1.4551 - val_accuracy: 0.0572\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 1.2001 - accuracy: 0.0662 - val_loss: 1.4475 - val_accuracy: 0.0525\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 9s 723ms/step - loss: 1.1926 - accuracy: 0.0669 - val_loss: 1.4256 - val_accuracy: 0.0612\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 9s 743ms/step - loss: 1.1815 - accuracy: 0.0695 - val_loss: 1.4296 - val_accuracy: 0.0583\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 9s 729ms/step - loss: 1.1700 - accuracy: 0.0707 - val_loss: 1.4254 - val_accuracy: 0.0623\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 9s 742ms/step - loss: 1.1617 - accuracy: 0.0720 - val_loss: 1.4281 - val_accuracy: 0.0623\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 9s 737ms/step - loss: 1.1527 - accuracy: 0.0731 - val_loss: 1.4199 - val_accuracy: 0.0641\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 9s 746ms/step - loss: 1.1422 - accuracy: 0.0741 - val_loss: 1.4135 - val_accuracy: 0.0664\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 9s 747ms/step - loss: 1.1344 - accuracy: 0.0750 - val_loss: 1.4052 - val_accuracy: 0.0651\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 9s 744ms/step - loss: 1.1221 - accuracy: 0.0759 - val_loss: 1.4001 - val_accuracy: 0.0668\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 9s 760ms/step - loss: 1.1112 - accuracy: 0.0772 - val_loss: 1.4005 - val_accuracy: 0.0658\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 9s 765ms/step - loss: 1.1066 - accuracy: 0.0774 - val_loss: 1.4007 - val_accuracy: 0.0667\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 9s 750ms/step - loss: 1.0961 - accuracy: 0.0776 - val_loss: 1.3973 - val_accuracy: 0.0662\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 9s 743ms/step - loss: 1.0850 - accuracy: 0.0786 - val_loss: 1.4002 - val_accuracy: 0.0664\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 9s 744ms/step - loss: 1.0796 - accuracy: 0.0792 - val_loss: 1.3854 - val_accuracy: 0.0677\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 9s 739ms/step - loss: 1.0698 - accuracy: 0.0799 - val_loss: 1.3853 - val_accuracy: 0.0696\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 9s 732ms/step - loss: 1.0610 - accuracy: 0.0803 - val_loss: 1.3790 - val_accuracy: 0.0699\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 9s 727ms/step - loss: 1.0530 - accuracy: 0.0810 - val_loss: 1.3708 - val_accuracy: 0.0709\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 1.0417 - accuracy: 0.0829 - val_loss: 1.3922 - val_accuracy: 0.0694\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 9s 736ms/step - loss: 1.0362 - accuracy: 0.0831 - val_loss: 1.3760 - val_accuracy: 0.0707\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 1.0272 - accuracy: 0.0843 - val_loss: 1.3695 - val_accuracy: 0.0723\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 1.0168 - accuracy: 0.0854 - val_loss: 1.3818 - val_accuracy: 0.0675\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 9s 718ms/step - loss: 1.0084 - accuracy: 0.0854 - val_loss: 1.3683 - val_accuracy: 0.0698\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 9s 718ms/step - loss: 1.0012 - accuracy: 0.0865 - val_loss: 1.3621 - val_accuracy: 0.0710\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 9s 713ms/step - loss: 0.9913 - accuracy: 0.0886 - val_loss: 1.3815 - val_accuracy: 0.0692\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.9842 - accuracy: 0.0889 - val_loss: 1.3586 - val_accuracy: 0.0738\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 9s 709ms/step - loss: 0.9742 - accuracy: 0.0894 - val_loss: 1.3534 - val_accuracy: 0.0754\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 8s 703ms/step - loss: 0.9668 - accuracy: 0.0905 - val_loss: 1.3571 - val_accuracy: 0.0744\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 9s 715ms/step - loss: 0.9581 - accuracy: 0.0913 - val_loss: 1.3609 - val_accuracy: 0.0756\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.9477 - accuracy: 0.0933 - val_loss: 1.3595 - val_accuracy: 0.0757\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 9s 720ms/step - loss: 0.9433 - accuracy: 0.0934 - val_loss: 1.3578 - val_accuracy: 0.0736\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.9338 - accuracy: 0.0930 - val_loss: 1.3543 - val_accuracy: 0.0757\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.9252 - accuracy: 0.0948 - val_loss: 1.3501 - val_accuracy: 0.0813\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 9s 713ms/step - loss: 0.9166 - accuracy: 0.0962 - val_loss: 1.3511 - val_accuracy: 0.0772\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 9s 717ms/step - loss: 0.9106 - accuracy: 0.0993 - val_loss: 1.3470 - val_accuracy: 0.0766\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 9s 721ms/step - loss: 0.8997 - accuracy: 0.1006 - val_loss: 1.3662 - val_accuracy: 0.0746\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.8911 - accuracy: 0.0998 - val_loss: 1.3642 - val_accuracy: 0.0741\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 8s 699ms/step - loss: 0.8902 - accuracy: 0.0978 - val_loss: 1.3446 - val_accuracy: 0.0762\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 9s 710ms/step - loss: 0.8784 - accuracy: 0.1023 - val_loss: 1.3501 - val_accuracy: 0.0751\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 9s 713ms/step - loss: 0.8691 - accuracy: 0.1020 - val_loss: 1.3469 - val_accuracy: 0.0768\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 0.8646 - accuracy: 0.1032 - val_loss: 1.3477 - val_accuracy: 0.0849\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 9s 722ms/step - loss: 0.8550 - accuracy: 0.1088 - val_loss: 1.3602 - val_accuracy: 0.0781\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.8473 - accuracy: 0.1065 - val_loss: 1.3474 - val_accuracy: 0.0751\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.8428 - accuracy: 0.1060 - val_loss: 1.3392 - val_accuracy: 0.0800\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.8337 - accuracy: 0.1131 - val_loss: 1.3443 - val_accuracy: 0.0778\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 9s 731ms/step - loss: 0.8267 - accuracy: 0.1101 - val_loss: 1.3421 - val_accuracy: 0.0765\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 9s 727ms/step - loss: 0.8217 - accuracy: 0.1110 - val_loss: 1.3475 - val_accuracy: 0.0773\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.8104 - accuracy: 0.1165 - val_loss: 1.3539 - val_accuracy: 0.0769\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 9s 715ms/step - loss: 0.8051 - accuracy: 0.1119 - val_loss: 1.3490 - val_accuracy: 0.0826\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 9s 729ms/step - loss: 0.7958 - accuracy: 0.1149 - val_loss: 1.3488 - val_accuracy: 0.0833\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.7886 - accuracy: 0.1140 - val_loss: 1.3533 - val_accuracy: 0.0769\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 9s 723ms/step - loss: 0.7837 - accuracy: 0.1240 - val_loss: 1.3527 - val_accuracy: 0.0748\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.7764 - accuracy: 0.1175 - val_loss: 1.3545 - val_accuracy: 0.0814\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.7678 - accuracy: 0.1189 - val_loss: 1.3678 - val_accuracy: 0.0801\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 9s 729ms/step - loss: 0.7613 - accuracy: 0.1253 - val_loss: 1.3558 - val_accuracy: 0.0776\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.7561 - accuracy: 0.1224 - val_loss: 1.3592 - val_accuracy: 0.0900\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.7462 - accuracy: 0.1245 - val_loss: 1.3521 - val_accuracy: 0.0900\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.7398 - accuracy: 0.1240 - val_loss: 1.3605 - val_accuracy: 0.0787\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 9s 710ms/step - loss: 0.7355 - accuracy: 0.1246 - val_loss: 1.3612 - val_accuracy: 0.0790\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 9s 710ms/step - loss: 0.7255 - accuracy: 0.1277 - val_loss: 1.3751 - val_accuracy: 0.0766\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 8s 701ms/step - loss: 0.7188 - accuracy: 0.1297 - val_loss: 1.3781 - val_accuracy: 0.0773\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 8s 688ms/step - loss: 0.7143 - accuracy: 0.1268 - val_loss: 1.3696 - val_accuracy: 0.1060\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 8s 690ms/step - loss: 0.7051 - accuracy: 0.1309 - val_loss: 1.3687 - val_accuracy: 0.0864\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 9s 709ms/step - loss: 0.7010 - accuracy: 0.1310 - val_loss: 1.3725 - val_accuracy: 0.0782\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.6944 - accuracy: 0.1337 - val_loss: 1.3565 - val_accuracy: 0.0866\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 9s 722ms/step - loss: 0.6879 - accuracy: 0.1356 - val_loss: 1.3627 - val_accuracy: 0.0811\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 0.6779 - accuracy: 0.1366 - val_loss: 1.3704 - val_accuracy: 0.0759\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 9s 714ms/step - loss: 0.6754 - accuracy: 0.1359 - val_loss: 1.3862 - val_accuracy: 0.0828\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.6624 - accuracy: 0.1399 - val_loss: 1.3843 - val_accuracy: 0.0845\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 9s 722ms/step - loss: 0.6604 - accuracy: 0.1412 - val_loss: 1.3781 - val_accuracy: 0.0834\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 9s 730ms/step - loss: 0.6541 - accuracy: 0.1406 - val_loss: 1.3841 - val_accuracy: 0.0788\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 0.6478 - accuracy: 0.1539 - val_loss: 1.3840 - val_accuracy: 0.0775\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 9s 719ms/step - loss: 0.6391 - accuracy: 0.1487 - val_loss: 1.3843 - val_accuracy: 0.0777\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 9s 713ms/step - loss: 0.6318 - accuracy: 0.1479 - val_loss: 1.3912 - val_accuracy: 0.0938\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 9s 716ms/step - loss: 0.6249 - accuracy: 0.1531 - val_loss: 1.3869 - val_accuracy: 0.0797\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 9s 725ms/step - loss: 0.6215 - accuracy: 0.1523 - val_loss: 1.4045 - val_accuracy: 0.1473\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 9s 725ms/step - loss: 0.6121 - accuracy: 0.1571 - val_loss: 1.4030 - val_accuracy: 0.0778\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.6082 - accuracy: 0.1656 - val_loss: 1.3984 - val_accuracy: 0.1199\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 0.6017 - accuracy: 0.1564 - val_loss: 1.4145 - val_accuracy: 0.0958\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.5959 - accuracy: 0.1607 - val_loss: 1.4068 - val_accuracy: 0.0920\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 9s 712ms/step - loss: 0.5880 - accuracy: 0.1595 - val_loss: 1.4173 - val_accuracy: 0.0960\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 8s 708ms/step - loss: 0.5787 - accuracy: 0.1563 - val_loss: 1.4196 - val_accuracy: 0.0773\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 9s 735ms/step - loss: 0.5806 - accuracy: 0.1636 - val_loss: 1.4169 - val_accuracy: 0.0736\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.5676 - accuracy: 0.1650 - val_loss: 1.4097 - val_accuracy: 0.0864\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 9s 726ms/step - loss: 0.5635 - accuracy: 0.1719 - val_loss: 1.4222 - val_accuracy: 0.0725\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 8s 706ms/step - loss: 0.5590 - accuracy: 0.1646 - val_loss: 1.4239 - val_accuracy: 0.1154\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 8s 692ms/step - loss: 0.5506 - accuracy: 0.1688 - val_loss: 1.4185 - val_accuracy: 0.0836\n"
     ]
    }
   ],
   "source": [
    "# Building the training model:\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
    "\n",
    "history = training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, \n",
    "                    batch_size = batch_size, \n",
    "                    epochs = epochs, \n",
    "                    validation_split = 0.2)\n",
    "\n",
    "training_model.save('/Users/alexander.fioto/Models/training_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from preprocessing import input_features_dict, target_features_dict, reverse_input_features_dict, reverse_target_features_dict, max_decoder_seq_length, input_docs, target_docs, input_tokens, target_tokens, max_encoder_seq_length\n",
    "#from training_model import decoder_inputs, decoder_lstm, decoder_dense, encoder_input_data, num_decoder_tokens, num_encoder_tokens\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "\n",
    "training_model = load_model('/Users/alexander.fioto/Models/training_model.h5')\n",
    "\n",
    "encoder_inputs = training_model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "latent_dim = 256\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(test_input):\n",
    "  # Encode the input as state vectors.\n",
    "  states_value = encoder_model.predict(test_input)\n",
    "\n",
    "  # Generate empty target sequence of length 1.\n",
    "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "  # Populate the first token of target sequence with the start token.\n",
    "  target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "\n",
    "  # Sampling loop for a batch of sequences\n",
    "  # (to simplify, here we assume a batch of size 1).\n",
    "  decoded_sentence = ''\n",
    "\n",
    "  stop_condition = False\n",
    "  while not stop_condition:\n",
    "    # Run the decoder model to get possible \n",
    "    # output tokens (with probabilities) & states\n",
    "    output_tokens, hidden_state, cell_state = decoder_model.predict(\n",
    "      [target_seq] + states_value)\n",
    "\n",
    "    # Choose token with highest probability\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "    decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "    # Exit condition: either hit max length\n",
    "    # or find stop token.\n",
    "    if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "      stop_condition = True\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # Update states\n",
    "    states_value = [hidden_state, cell_state]\n",
    "\n",
    "  return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "\n",
    "\n",
    "    exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\", 'end')\n",
    "\n",
    "    def start_chat(self):\n",
    "        user_response = input(\"Hi, I'm a chatbot trained on dialog from Seinfeld. Would you like to chat with me?\\n\")\n",
    "    \n",
    "        if user_response.lower() in self.negative_responses:\n",
    "            print(\"Ok, have a great day!\")\n",
    "            return\n",
    "    \n",
    "        user_response = input('Great! I am still a work in progress. Try using a lot of different words when chatting with me. Ok, what do you want to talk about?')\n",
    "    \n",
    "        self.chat(user_response)\n",
    "  \n",
    "    def chat(self, reply):\n",
    "        while not self.make_exit(reply):\n",
    "            reply = input(self.generate_response(reply))\n",
    "    \n",
    "\n",
    "    def string_to_matrix(self, user_input):\n",
    "        tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "        user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "        for timestep, token in enumerate(tokens):\n",
    "            if token in input_features_dict:\n",
    "                user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "\n",
    "        return user_input_matrix\n",
    "\n",
    "    def generate_response(self, user_input):\n",
    "        input_matrix = self.string_to_matrix(user_input)\n",
    "        states_value = encoder_model.predict(input_matrix)\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, target_features_dict['<START>']] = 1.0\n",
    "    \n",
    "        chatbot_response = ''\n",
    "\n",
    "        stop_condition = False\n",
    "\n",
    "        while not stop_condition:\n",
    "\n",
    "            output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "            chatbot_response += \" \" + sampled_token\n",
    "\n",
    "            if (sampled_token == '<END>' or len(chatbot_response) > max_decoder_seq_length):\n",
    "                stop_condition = True\n",
    "\n",
    "                target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "                target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "            if '<END>' in chatbot_response:\n",
    "                chatbot_response = chatbot_response.replace('<END>', '')\n",
    "\n",
    "            punctuations = [' ?', ' .', ' !', ' ,']            \n",
    "            for punctuation in punctuations:\n",
    "                if punctuation in chatbot_response:\n",
    "                    chatbot_response = chatbot_response.replace(punctuation, punctuation[-1])\n",
    "\n",
    "\n",
    "            states_value = [hidden_state, cell_state]\n",
    "\n",
    "        return chatbot_response\n",
    "  \n",
    "    def make_exit(self, reply):\n",
    "        for exit_command in self.exit_commands:\n",
    "            if exit_command in reply:\n",
    "                print(\"Ok, have a great day!\")\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot trained on dialog from Seinfeld. Would you like to chat with me?\n",
      " Hi\n",
      "Great! I am still a work in progress. Try using a lot of different words when chatting with me. Ok, what do you want to talk about? what is up\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-7dcd8258feef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-ebdca281bcd4>\u001b[0m in \u001b[0;36mstart_chat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0muser_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Great! I am still a work in progress. Try using a lot of different words when chatting with me. Ok, what do you want to talk about?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-ebdca281bcd4>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, reply)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m         )\n\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "chat.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
