{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = '/Users/alexander.fioto/Models/Labeled-Seinfeld-Model/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aitextgen:Loading GPT-2 model from provided /Users/alexander.fioto/Models/Labeled-Seinfeld-Model/pytorch_model.bin.\n",
      "INFO:aitextgen:Using a custom tokenizer.\n"
     ]
    }
   ],
   "source": [
    "ai = aitextgen(model= fp + \"pytorch_model.bin\",\n",
    "               config = fp + 'config.json', \n",
    "               vocab_file=fp + 'aitextgen-vocab.json',\n",
    "               merges_file=fp + 'aitextgen-merges.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mALEX: tell me about yourself\u001b[0m.\n",
      "\n",
      "\n",
      "JERRY: What?\n",
      "\n",
      "\n",
      "GEORGE: You're going to get me a sample of Jerry\n"
     ]
    }
   ],
   "source": [
    "ai.generate(prompt='ALEX: tell me about yourself',\n",
    "            temperature = .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeinfeldChatbot():\n",
    "    def __init__(self, name='USER: ', fp='/Users/alexander.fioto/Models/Labeled-Seinfeld-Model/', temperature = .4):\n",
    "        self.user_name_title = name\n",
    "        self.fp = fp\n",
    "        self.temperature = temperature\n",
    "        self.exit_commands = ['bye', 'exit', 'i have to go', 'later', 'gtg', 'stop']\n",
    "        self.punctuation = ['.', '!', '?']\n",
    "        self.model = aitextgen(model= fp + \"pytorch_model.bin\",\n",
    "                               config = fp + 'config.json', \n",
    "                               vocab_file=fp + 'aitextgen-vocab.json',\n",
    "                               merges_file=fp + 'aitextgen-merges.txt')\n",
    "        print(\"Model Loaded!\")\n",
    "        \n",
    "    \n",
    "    def change_temp(self, temp):\n",
    "        if temp < 0 or temp > 1:\n",
    "            raise ValueError('Value must be greater than 0 and less than or equal to 1')\n",
    "        else:\n",
    "            self.temperature = temp\n",
    "        \n",
    "        \n",
    "    def get_name(self):\n",
    "        name = input(\"GEORGE: What\\'s your name, pal?\")\n",
    "        self.name = name\n",
    "        self.user_name_title = name.upper() + ': '\n",
    "    \n",
    "    def chat(self):\n",
    "        self.get_name()\n",
    "        print(f'JERRY: What do you want, {self.name}?')\n",
    "        chat = True\n",
    "        while chat:\n",
    "            text_input = input()\n",
    "            if text_input in self.exit_commands:\n",
    "                chat = False\n",
    "                print('KRAMER: Who turns down a junior mint?')\n",
    "                \n",
    "            else:\n",
    "                if text_input[-1] not in self.punctuation:\n",
    "                    text_input += '.'\n",
    "                self.model.generate(prompt = f'{self.user_name_title}' + text_input,\n",
    "                                    temperature = .4)\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aitextgen:Loading GPT-2 model from provided /Users/alexander.fioto/Models/Labeled-Seinfeld-Model/pytorch_model.bin.\n",
      "INFO:aitextgen:Using a custom tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded!\n"
     ]
    }
   ],
   "source": [
    "bot = SeinfeldChatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "GEORGE: What's  your name, pal? Alex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JERRY: What do you want, Alex?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I want to talk to you!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mALEX: I want to talk to you!\u001b[0m\n",
      "\n",
      "\n",
      "JERRY: But you said, it can be very serious.\n",
      "\n",
      "\n",
      "ELAINE: Okay,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " This is silly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mALEX: This is silly.\u001b[0m\n",
      "\n",
      "\n",
      "JERRY: I know.\n",
      "\n",
      "\n",
      "BANIA: Did you ask Kramer?\n",
      "\n",
      "\n",
      "JERRY: No,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I did not ask Kramer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mALEX: I did not ask Kramer.\u001b[0m But when you're getting that look. You gotta look me to the end?\n",
      "\n",
      "\n",
      "GEORGE: No.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I think you should\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mALEX: I think you should.\u001b[0m Okay, bye.\n",
      "\n",
      "\n",
      "JERRY: Why don't you mind your own business?\n",
      "\n",
      "\n",
      "KRAMER: I\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " How hot is it outside\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mALEX: How hot is it outside.\u001b[0m\n",
      "\n",
      "\n",
      "JERRY: Oh, it's a better thing than that.\n",
      "\n",
      "\n",
      "GEORGE:  Oh,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KRAMER: Well I'm out of here too!\n"
     ]
    }
   ],
   "source": [
    "bot.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
